defaults:
  - base_model

arch:
  type: enc
  encoder: cnn
lib: factored_rl
flatten_input: false
cnn:
  activation:
    - _target_: torch.nn.ReLU
  final_activation:
    - _target_: torch.nn.ReLU
mlp:
  activation:
    - _target_: torch.nn.ReLU
  final_activation:
    - _target_: torch.nn.Tanh
qnet:
  n_hidden_layers: 1
  n_units_per_layer: 64
  activation:
    - _target_: torch.nn.ReLU
  final_activation: null
