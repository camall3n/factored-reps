defaults:
  - base_model

name: mlp
lib: factored_rl
architecture: mlp
flatten_input: true
mlp:
  n_hidden_layers: 1
  n_units_per_layer: 64
  activation:
    - _target_: torch.nn.Tanh
  final_activation: null
